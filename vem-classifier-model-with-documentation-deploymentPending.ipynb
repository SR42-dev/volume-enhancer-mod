{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Volume Enhancer Mod\n## An analysis on the viability of a deep learning model for the prediction of preferred user volume when listening to music of various origins.","metadata":{}},{"cell_type":"markdown","source":"Some context for this project ...\n\n- When listening to music on streaming services, a closer look at the users' volume preferences will lead you to notice a pattern. Most of us change our preferences for listening volume based on the origin of the song e.g.; classical piano is more pleasant to the ear at a lower volume while heavy metal will likely have you turning the knob the other way.\n\n- These patterns certainly don't follow any regular regression plot of any sort. While the baseline varies from person to person based on their comfort of hearing, the general trend seemingly remains the same.\n\n- Due to this unstructured distribution of data that remains elusive to accurate prediction by regression algorithms, a neural structure is desirable for evaluation. This experiment seeks to prove/disprove that very viability.","metadata":{}},{"cell_type":"code","source":"# library imports\nimport librosa\nimport torch as tc\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport seaborn as sns\nfrom torch import optim\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:22.804359Z","iopub.execute_input":"2022-02-14T14:08:22.805152Z","iopub.status.idle":"2022-02-14T14:08:25.997095Z","shell.execute_reply.started":"2022-02-14T14:08:22.805058Z","shell.execute_reply":"2022-02-14T14:08:25.996141Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Analysis :\nIn order to evaluate the viability of the concept behind the model as well as the compatibility of the independent variables with the same, we have to test our audio features against the dependent variable i.e.; user volume.\n\nTo carry out this evaluation, we will start with data import & preliminary datatype evaluation. We're ideally looking for float values here.","metadata":{}},{"cell_type":"code","source":"# data upload\ndataPath = '../input/random-testing-data1/features_30_sec_randEdit.csv'\naudioData = pd.read_csv(dataPath)\naudioData[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:25.999217Z","iopub.execute_input":"2022-02-14T14:08:25.999455Z","iopub.status.idle":"2022-02-14T14:08:26.075876Z","shell.execute_reply.started":"2022-02-14T14:08:25.999423Z","shell.execute_reply":"2022-02-14T14:08:26.075230Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# display datatypes\naudioData.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:26.077010Z","iopub.execute_input":"2022-02-14T14:08:26.077396Z","iopub.status.idle":"2022-02-14T14:08:26.085229Z","shell.execute_reply.started":"2022-02-14T14:08:26.077357Z","shell.execute_reply":"2022-02-14T14:08:26.084440Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Correlation testing :\nAt this stage, we need to find the correlation coefficients of all possible pairings of independent & dependent variables, i.e; find the Pearson's correlation coefficient of all variable pairings with user volume.\n\nAs we need only find the pairs most suitable to be used as inputs for the model with respect to training efficiency and aren't focused on the exact numbers behind said pairs, we can filter out all reflexive & symmetric groups and highlight just the cells with an R value of greater than 0.8 (tentative). \n\nDo note that correlation analysis doesn't take into account the effect of variables outside the system being evaluated. It is also relatively inaccurate while testing for non-linear relationships. Hence, some leeway in the threshold R value may be warranted.\n\nThat being said, we're only interested in highlighted cells in the last row here.","metadata":{}},{"cell_type":"code","source":"# correlogram filtering out only pairs with a correlation coefficient of greater than 0.8 or lesser than -0.8\ncorrDataFrame = audioData.corr(method ='pearson')\ncorrDataFrame[np.abs(corrDataFrame) < 0.8] = 0\n\nmask = np.zeros_like(corrDataFrame, dtype = np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize = (20,20))\nsns.heatmap(corrDataFrame, cmap=\"coolwarm\", mask=mask)\n\n# consider applying transforms to the dataset to try and squeeze out any correlations","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:26.087770Z","iopub.execute_input":"2022-02-14T14:08:26.088250Z","iopub.status.idle":"2022-02-14T14:08:29.056546Z","shell.execute_reply.started":"2022-02-14T14:08:26.088210Z","shell.execute_reply":"2022-02-14T14:08:29.055792Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model design : \nFrom the correlogram above, we shall choose **only the highlighted columns** from the 'volume' row to be our independent variables. As observed from the datatype test from earlier, the only categorical variable in the dataset is genre. \n\nIntuitively, genre **does play a significant role** in our preferences for ideal volume. Therefore, we shall include it as a label encoded input.\n\nAs most electronic devices represent volume as an **integer between 0 & 100**, we shall construct a **classifier** to predict the volume and will have to one-hot encode the output as such.","metadata":{}},{"cell_type":"code","source":"# train/test data loading\ndf = pd.read_csv(dataPath)\ntrain = df.sample(frac=0.5,random_state=100) # random state is a seed value\ntest = df.drop(train.index)\n\n# dependent variable, categorical (0-100) (one hot encoded)\nYtest = test['volume']\nYtest = pd.get_dummies(Ytest)\nYtest = Ytest.to_numpy()\n\nYtrain = train['volume']\nYtrain = pd.get_dummies(Ytrain)\nYtrain = Ytrain.to_numpy()\n\n# independent variable 1, categorical (label encoded)\n# note : [blues:0, classical:1, country:2, disco:3, hiphop:4, jazz:5, metal:6, pop:7, reggae:8, rock:9]\nle = preprocessing.LabelEncoder()\nX1test = le.fit_transform(test['label'])\nX1train = le.fit_transform(train['label'])\n\n# independent variable 2, numerical\nX2test = test['chroma_stft_mean'].to_numpy()\nX2train = train['chroma_stft_mean'].to_numpy()\n\n# add on the remaining relevant variables here","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.057558Z","iopub.execute_input":"2022-02-14T14:08:29.057781Z","iopub.status.idle":"2022-02-14T14:08:29.090536Z","shell.execute_reply.started":"2022-02-14T14:08:29.057748Z","shell.execute_reply":"2022-02-14T14:08:29.089842Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# declaring constants\nnumInputs = 2 # number of input variables based on correlation test\nNtest = 500 # number of testing entries\nNtrain = 500 # number of training entries","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.091613Z","iopub.execute_input":"2022-02-14T14:08:29.091863Z","iopub.status.idle":"2022-02-14T14:08:29.096177Z","shell.execute_reply.started":"2022-02-14T14:08:29.091827Z","shell.execute_reply":"2022-02-14T14:08:29.095486Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# data reshaping\nXtest = np.dstack([X1test,X2test]) # add on all the independent testing variables in this list\nXtest = Xtest.reshape(Ntest,numInputs) \n\nXtrain = np.dstack([X1train,X2train]) # add on all the independent training variables in this list\nXtrain = Xtrain.reshape(Ntrain,numInputs) \n\nif (Ytest.shape[1] == Ytrain.shape[1]) :\n    \n    print(f'Number of classes : {Ytest.shape[1]}\\n')\n    # declaring number of outputs based on the results of one hot encoding\n    numOutputs = 99\n    \nelse :\n    \n    print('Re-execute test/train split\\n')\n    \nYtest = Ytest.reshape(Ntest, 99) # one dependent test variable\nYtrain = Ytrain.reshape(Ntrain, 99) # one dependent train variable\n\n# data type conversion\nxtest = tc.from_numpy(Xtest.astype(np.float32))\nxtrain = tc.from_numpy(Xtrain.astype(np.float32))\n\nytest = tc.from_numpy(Ytest.astype(np.float32))\nytrain = tc.from_numpy(Ytrain.astype(np.float32))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.097317Z","iopub.execute_input":"2022-02-14T14:08:29.098042Z","iopub.status.idle":"2022-02-14T14:08:29.110338Z","shell.execute_reply.started":"2022-02-14T14:08:29.098000Z","shell.execute_reply":"2022-02-14T14:08:29.109481Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model architecture :\n\nAs the data is organizable as a plain stack of layers with singular input & output tensors, a sequential model is suitable for our purposes.\n\n- ReLU activation will suffice for the hidden layers.\n- As the model is intended to be a classifier, a sigmoid activation function seems to be the intuitive choice of activation for the output layer, but testing has shown that a ReLU produces higher accuracies.\n- Dropouts are preferable to prevent overfitting.\n\nAs such, we shall build a **sequential linear ReLU stack**.","metadata":{}},{"cell_type":"code","source":"# model definition\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs, numOutputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(128, numOutputs),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.111783Z","iopub.execute_input":"2022-02-14T14:08:29.112057Z","iopub.status.idle":"2022-02-14T14:08:29.122434Z","shell.execute_reply.started":"2022-02-14T14:08:29.112021Z","shell.execute_reply":"2022-02-14T14:08:29.121625Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Initializing the training parameters :\nThere's two aspect choices to consider at this stage -\n\n- **Loss function :** As this is a multi-class classification problem which requires small deviations from the true value to be exaggerated, a Kullback-Leibler divergence loss function is most appropriate. Preliminary testing confirms it's positive impact on model accuracy.\n- **Optimizer :** Due to one hot encoding of 100 classes resulting in a sparse data distribution, Adam is seemingly preferable to stochastic gradient descent.","metadata":{}},{"cell_type":"code","source":"# error function & optimizer\nmodel = NeuralNetwork(numInputs, numOutputs)\ne_func = tc.nn.KLDivLoss()\noptim = tc.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.123452Z","iopub.execute_input":"2022-02-14T14:08:29.123649Z","iopub.status.idle":"2022-02-14T14:08:29.157997Z","shell.execute_reply.started":"2022-02-14T14:08:29.123621Z","shell.execute_reply":"2022-02-14T14:08:29.157352Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Note :** This script is GPU compatible.","metadata":{}},{"cell_type":"code","source":"# move model to GPU\ndevice = tc.device(\"cuda\" if tc.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:29.160848Z","iopub.execute_input":"2022-02-14T14:08:29.161431Z","iopub.status.idle":"2022-02-14T14:08:32.035487Z","shell.execute_reply.started":"2022-02-14T14:08:29.161372Z","shell.execute_reply":"2022-02-14T14:08:32.034735Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# model training/testing loop\nep = 1000\ntrain_losses, test_losses, accuracies = [], [], []\n\nfor e in range(ep+1) :\n    \n    # training model\n    running_loss = 0\n    xtrain, ytrain = xtrain.to(device), ytrain.to(device)\n    \n    optim.zero_grad() \n    \n    output = model(xtrain) \n    loss = e_func(output, ytrain)\n    \n    loss.backward() \n    optim.step() \n    \n    running_loss += loss.item()\n    train_losses.append(running_loss/len(ytrain))\n    \n    # testing model\n    test_loss, accuracy = 0, 0\n    \n    with tc.no_grad():\n            \n        model.eval()\n        xtest, ytest = xtest.to(device), ytest.to(device)\n        output = model(xtest) \n        test_loss += e_func(output, ytest)\n        \n        _, predictions = tc.max(output, 1)\n        _, targets = tc.max(ytest, 1)\n        accuracy += (predictions == targets).sum().item()\n        \n        test_losses.append(test_loss/len(ytest))\n        accuracies.append(accuracy/len(ytest))\n        model.train()\n\n    print(f'Epoch: {e}/{ep}\\n',\n          f'Training loss: {running_loss/len(ytrain)}\\n',\n          f'Test loss: {test_loss/len(ytest)}\\n',\n          f'Accuracy: {accuracy/len(ytest)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:32.036794Z","iopub.execute_input":"2022-02-14T14:08:32.037197Z","iopub.status.idle":"2022-02-14T14:08:36.734628Z","shell.execute_reply.started":"2022-02-14T14:08:32.037158Z","shell.execute_reply":"2022-02-14T14:08:36.733942Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# plot train & test loss per iteration\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:36.735988Z","iopub.execute_input":"2022-02-14T14:08:36.736236Z","iopub.status.idle":"2022-02-14T14:08:36.971952Z","shell.execute_reply.started":"2022-02-14T14:08:36.736201Z","shell.execute_reply":"2022-02-14T14:08:36.971258Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# plot testing accuracy\nplt.plot(accuracies, label='Model accuracy')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:36.973084Z","iopub.execute_input":"2022-02-14T14:08:36.973611Z","iopub.status.idle":"2022-02-14T14:08:37.201126Z","shell.execute_reply.started":"2022-02-14T14:08:36.973560Z","shell.execute_reply":"2022-02-14T14:08:37.200268Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# save model\nPATH = '../output/model.pth' # input directory in which the model is to be saved\ntc.save(model, PATH)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:37.202455Z","iopub.execute_input":"2022-02-14T14:08:37.202699Z","iopub.status.idle":"2022-02-14T14:08:37.359519Z","shell.execute_reply.started":"2022-02-14T14:08:37.202666Z","shell.execute_reply":"2022-02-14T14:08:37.358321Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Testing model deployment :\nThis section is implemented as follows -\n\n- The model class is declared & the model is loaded from storage.\n- A sample MP3 file is loaded using librosa & visualized.\n- The data is processed to extract the relevant features identified in the correlogram earlier.\n- The processed data is converted to the appropriate tensors for input into the model.\n- A prediction is obtained from this data.","metadata":{}},{"cell_type":"code","source":"# model class\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs, numOutputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(128, numOutputs),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:37.360920Z","iopub.status.idle":"2022-02-14T14:08:37.361360Z","shell.execute_reply.started":"2022-02-14T14:08:37.361135Z","shell.execute_reply":"2022-02-14T14:08:37.361159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nPATH = '../output/model.pth' # directory in which the model is saved\nmodel = tc.load(PATH)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:37.362857Z","iopub.status.idle":"2022-02-14T14:08:37.363306Z","shell.execute_reply.started":"2022-02-14T14:08:37.363064Z","shell.execute_reply":"2022-02-14T14:08:37.363089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading sample file for testing\nfname = '../input/test-audio/Kalimba.mp3'\ngenre = '' # specify genre\nSR = 22050\ndata, _ = librosa.load(fname, sr=SR, mono=True)\n\n# visualizing sample mp3\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(y = data, sr = 22050, color = \"#A300F9\")\nplt.title(\"Sound Waves in sample\", fontsize = 10)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:37.364381Z","iopub.status.idle":"2022-02-14T14:08:37.365001Z","shell.execute_reply.started":"2022-02-14T14:08:37.364747Z","shell.execute_reply":"2022-02-14T14:08:37.364772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The prediction function :\nImplementation guidelines -\n\n- Input : librosa loaded audio file, string containing genre.\n- Relevant feature extraction using librosa's in-built functions.\n- Genre is encoded as follows : [blues:0, classical:1, country:2, disco:3, hiphop:4, jazz:5, metal:6, pop:7, reggae:8, rock:9]\n- The data is processed in an identical manner to the data loading & data reshaping sections of the model design chapter of this notebook to produce the necessary tensors.\n- The tensor(s) are fed to the model and a prediction is returned.\n- Output : Integer value from 0 to 100.","metadata":{}},{"cell_type":"code","source":"# function to take an mp3 file as a parameter and return predicted volume by calling saved model\ndef predictVolume(data, genre) :\n    \n    # getting all necessary model input values in the correct data format\n    \n    return prediction","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:08:37.366227Z","iopub.status.idle":"2022-02-14T14:08:37.366896Z","shell.execute_reply.started":"2022-02-14T14:08:37.366639Z","shell.execute_reply":"2022-02-14T14:08:37.366663Z"},"trusted":true},"execution_count":null,"outputs":[]}]}