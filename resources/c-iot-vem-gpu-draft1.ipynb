{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# library imports\nimport os\nimport glob\nimport cv2\nimport librosa\nimport torch as tc\nimport torchvision\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport seaborn as sns\nimport librosa.display\nfrom torch import optim\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T18:21:03.800690Z","iopub.execute_input":"2022-02-07T18:21:03.800971Z","iopub.status.idle":"2022-02-07T18:21:03.808337Z","shell.execute_reply.started":"2022-02-07T18:21:03.800943Z","shell.execute_reply":"2022-02-07T18:21:03.807506Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Superficial data analysis**","metadata":{}},{"cell_type":"code","source":"# data upload\naudioData = pd.read_csv('../input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv')\naudioData[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:35.243627Z","iopub.execute_input":"2022-02-07T17:44:35.244132Z","iopub.status.idle":"2022-02-07T17:44:35.365459Z","shell.execute_reply.started":"2022-02-07T17:44:35.244086Z","shell.execute_reply":"2022-02-07T17:44:35.364606Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"audioData.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:35.367039Z","iopub.execute_input":"2022-02-07T17:44:35.367520Z","iopub.status.idle":"2022-02-07T17:44:35.378443Z","shell.execute_reply.started":"2022-02-07T17:44:35.367475Z","shell.execute_reply":"2022-02-07T17:44:35.377548Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Correlation testing**","metadata":{}},{"cell_type":"code","source":"# general correlogram \ncorrDataFrame = audioData.corr(method ='pearson')\nplt.figure(figsize = (20,20))\nsns.heatmap(corrDataFrame, cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:35.380659Z","iopub.execute_input":"2022-02-07T17:44:35.380901Z","iopub.status.idle":"2022-02-07T17:44:38.232895Z","shell.execute_reply.started":"2022-02-07T17:44:35.380874Z","shell.execute_reply":"2022-02-07T17:44:38.231996Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# filtering only the pairs which have high correlation\n\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\n\ntopCorr = get_top_abs_correlations(corrDataFrame, 221) # 221 as the 221st entry was the last one greater than 0.8\ntopCorr = pd.DataFrame(topCorr)\npd.set_option('display.max_rows', None)\ntopCorr","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.234504Z","iopub.execute_input":"2022-02-07T17:44:38.234823Z","iopub.status.idle":"2022-02-07T17:44:38.331856Z","shell.execute_reply.started":"2022-02-07T17:44:38.234784Z","shell.execute_reply":"2022-02-07T17:44:38.331272Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"'''\n\nNotes :\n\n- Use Ctrl + F to find the rows with the desired dependent variable.\n- Consider only the elements paired with them as independent variables for the model.\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.332785Z","iopub.execute_input":"2022-02-07T17:44:38.333661Z","iopub.status.idle":"2022-02-07T17:44:38.339873Z","shell.execute_reply.started":"2022-02-07T17:44:38.333616Z","shell.execute_reply":"2022-02-07T17:44:38.339087Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Model training**","metadata":{}},{"cell_type":"code","source":"# train/test data loading\ndf = pd.read_csv('../input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv')\ntrain = df.sample(frac=0.8,random_state=200) # random state is a seed value\ntest = df.drop(train.index)\n\n# dependent variable, categorical (0-100)\nYtest = test['volume'].to_numpy()\nYtrain = train['volume'].to_numpy()\n\n# independent variable 1, categorical\nle = preprocessing.LabelEncoder()\nX1test = le.fit_transform(test['label'])\nX1train = le.fit_transform(train['label'])\n\n# independent variable 2, numerical\nX2test = test['rms_mean'].to_numpy()\nX2train = train['rms_mean'].to_numpy()\n\n# add on the remaining relevant variables here","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:38:55.869551Z","iopub.execute_input":"2022-02-07T18:38:55.869809Z","iopub.status.idle":"2022-02-07T18:38:55.900729Z","shell.execute_reply.started":"2022-02-07T18:38:55.869783Z","shell.execute_reply":"2022-02-07T18:38:55.900093Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# declaring constants\nnumInputs = 2 # number of input variables based on correlation test\nN = 1000 # number of entries","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data reshaping\nXtest = np.dstack([X1test,X2test]) # add on all the independent testing variables in this list\nXtest = Xtest.reshape(N,numInputs) \n\nXtrain = np.dstack([X1train,X2train]) # add on all the independent training variables in this list\nXtrain = Xtrain.reshape(N,numInputs) \n\nYtest = Ytest.reshape(N, 1) # one dependent test variable\nYtrain = Ytrain.reshape(N, 1) # one dependent train variable\n\n# data type conversion\nxtest = tc.from_numpy(Xtest.astype(np.float32))\nxtrain = tc.from_numpy(Xtrain.astype(np.float32))\n\nytest = tc.from_numpy(Ytest.astype(np.float32))\nytrain = tc.from_numpy(Ytrain.astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.355010Z","iopub.execute_input":"2022-02-07T17:44:38.355618Z","iopub.status.idle":"2022-02-07T17:44:38.365902Z","shell.execute_reply.started":"2022-02-07T17:44:38.355586Z","shell.execute_reply":"2022-02-07T17:44:38.365262Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# model definition\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 100),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.382006Z","iopub.execute_input":"2022-02-07T17:44:38.382278Z","iopub.status.idle":"2022-02-07T17:44:38.392853Z","shell.execute_reply.started":"2022-02-07T17:44:38.382249Z","shell.execute_reply":"2022-02-07T17:44:38.391948Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# error function & optimizer\nmodel = NeuralNetwork(numInputs)\ne_func = tc.nn.MSELoss()\noptim = tc.optim.SGD(model.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:55:37.746711Z","iopub.execute_input":"2022-02-07T17:55:37.747465Z","iopub.status.idle":"2022-02-07T17:55:37.785745Z","shell.execute_reply.started":"2022-02-07T17:55:37.747419Z","shell.execute_reply":"2022-02-07T17:55:37.785144Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# move model to GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model training \nep = 1000 \ntrain_losses, test_losses, accuracies = [], [], []\n\nfor e in range(ep) :\n    \n    # training model\n    running_loss = 0\n    xtrain, ytrain = xtrain.to(device), ytrain.to(device)\n    \n    optim.zero_grad() \n    \n    output = model(xtrain) \n    loss = e_func(output, ytrain)\n    \n    loss.backward() \n    optim.step() \n    \n    running_loss += loss.item()\n    train_losses.append(running_loss/len(ytrain))\n    \n    # testing model\n    test_loss, accuracy = 0, 0\n    \n    with torch.no_grad():\n            \n        model.eval()\n        xtest, ytest = xtest.to(device), ytest.to(device)\n        output = model(xtest) \n        test_loss += e_func(output, ytest)\n        \n        ps = torch.exp(output)       \n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == ytest.view(*top_class.shape)\n        accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n    test_losses.append(test_loss/len(ytest))\n    accuracies.append(accuracy/len(ytest))\n    model.train()\n        \n    print(f'Epoch: {e}/{epochs}',\n          f'Training loss: {running_loss/len(ytrain)}',\n          f'Test loss: {test_loss/len(ytest)}',\n          f'Accuracy: {accuracy/len(ytest)}')    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:55:46.471063Z","iopub.execute_input":"2022-02-07T17:55:46.471350Z","iopub.status.idle":"2022-02-07T17:55:46.498296Z","shell.execute_reply.started":"2022-02-07T17:55:46.471320Z","shell.execute_reply":"2022-02-07T17:55:46.497308Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# plot train & test loss per iteration\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.591458Z","iopub.status.idle":"2022-02-07T17:44:38.591765Z","shell.execute_reply.started":"2022-02-07T17:44:38.591607Z","shell.execute_reply":"2022-02-07T17:44:38.591623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot testing accuracy\nplt.plot(accuracies, label='Testing accuracy')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.592754Z","iopub.status.idle":"2022-02-07T17:44:38.593084Z","shell.execute_reply.started":"2022-02-07T17:44:38.592888Z","shell.execute_reply":"2022-02-07T17:44:38.592904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save model\nPATH = '' # input directory in which the model is to be saved\ntorch.save(model, PATH)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Testing model deployment**","metadata":{}},{"cell_type":"code","source":"# model class\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 100),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nPATH = '' # directory in which the model is saved\nmodel = torch.load(PATH)\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading sample file for testing\nfname = '../input/test-audio/Kalimba.mp3'\nSR = 22050\ndata, _ = librosa.load(fname, sr=SR, mono=True)\n\n# visualizing sample mp3\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(y = data, sr = 22050, color = \"#A300F9\")\nplt.title(\"Sound Waves in sample\", fontsize = 10)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T17:44:38.594918Z","iopub.status.idle":"2022-02-07T17:44:38.595259Z","shell.execute_reply.started":"2022-02-07T17:44:38.595093Z","shell.execute_reply":"2022-02-07T17:44:38.595114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to take an mp3 file as a parameter and return predicted volume by calling saved model\ndef predictVolume(data) :\n    \n    # getting all necessary model input values in the correct data format\n    \n    return prediction","metadata":{"execution":{"iopub.status.busy":"2022-02-07T19:46:11.370607Z","iopub.execute_input":"2022-02-07T19:46:11.372792Z","iopub.status.idle":"2022-02-07T19:46:11.383304Z","shell.execute_reply.started":"2022-02-07T19:46:11.372692Z","shell.execute_reply":"2022-02-07T19:46:11.382166Z"},"trusted":true},"execution_count":36,"outputs":[]}]}