{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# library imports\nimport librosa\nimport torch as tc\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport seaborn as sns\nfrom torch import optim\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T20:34:31.073263Z","iopub.execute_input":"2022-02-10T20:34:31.074114Z","iopub.status.idle":"2022-02-10T20:34:31.080114Z","shell.execute_reply.started":"2022-02-10T20:34:31.074068Z","shell.execute_reply":"2022-02-10T20:34:31.079283Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":"**Superficial data analysis**","metadata":{}},{"cell_type":"code","source":"# data upload\ndataPath = '../input/random-testing-data/features_30_sec_randEdit.csv'\naudioData = pd.read_csv(dataPath)\naudioData[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:31.085890Z","iopub.execute_input":"2022-02-10T20:34:31.086745Z","iopub.status.idle":"2022-02-10T20:34:31.140610Z","shell.execute_reply.started":"2022-02-10T20:34:31.086694Z","shell.execute_reply":"2022-02-10T20:34:31.139721Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"audioData.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:31.142697Z","iopub.execute_input":"2022-02-10T20:34:31.143593Z","iopub.status.idle":"2022-02-10T20:34:31.155805Z","shell.execute_reply.started":"2022-02-10T20:34:31.143542Z","shell.execute_reply":"2022-02-10T20:34:31.154816Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"markdown","source":"**Correlation testing**","metadata":{}},{"cell_type":"code","source":"# general correlogram \ncorrDataFrame = audioData.corr(method ='pearson')\nplt.figure(figsize = (20,20))\nsns.heatmap(corrDataFrame, cmap=\"Blues\")","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:31.159313Z","iopub.execute_input":"2022-02-10T20:34:31.159561Z","iopub.status.idle":"2022-02-10T20:34:33.929044Z","shell.execute_reply.started":"2022-02-10T20:34:31.159530Z","shell.execute_reply":"2022-02-10T20:34:33.928345Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"# correlogram filtering out only pairs with a correlation coefficient of greater than 0.8 or lesser than -0.8\ncorrDataFrame = audioData.corr(method ='pearson')\ncorrDataFrame[np.abs(corrDataFrame) < 0.8] = 0\n\nmask = np.zeros_like(corrDataFrame, dtype = np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize = (20,20))\nsns.heatmap(corrDataFrame, cmap=\"coolwarm\", mask=mask)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:33.930344Z","iopub.execute_input":"2022-02-10T20:34:33.930719Z","iopub.status.idle":"2022-02-10T20:34:36.582644Z","shell.execute_reply.started":"2022-02-10T20:34:33.930683Z","shell.execute_reply":"2022-02-10T20:34:36.581938Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"# filtering only the pairs which have high correlation\n\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\n\ntopCorr = get_top_abs_correlations(corrDataFrame, 221) # 221 as the 221st entry was the last one greater than 0.8\ntopCorr = pd.DataFrame(topCorr)\npd.set_option('display.max_rows', None)\n# topCorr","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.585200Z","iopub.execute_input":"2022-02-10T20:34:36.585981Z","iopub.status.idle":"2022-02-10T20:34:36.641347Z","shell.execute_reply.started":"2022-02-10T20:34:36.585936Z","shell.execute_reply":"2022-02-10T20:34:36.640473Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"'''\n\nNotes :\n\n- Use Ctrl + F to find the rows with the desired dependent variable.\n- Consider only the elements paired with them as independent variables for the model.\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.642750Z","iopub.execute_input":"2022-02-10T20:34:36.643536Z","iopub.status.idle":"2022-02-10T20:34:36.650332Z","shell.execute_reply.started":"2022-02-10T20:34:36.643480Z","shell.execute_reply":"2022-02-10T20:34:36.649431Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"**Model training**","metadata":{}},{"cell_type":"code","source":"# train/test data loading\ndf = pd.read_csv(dataPath)\ntrain = df.sample(frac=0.8,random_state=200) # random state is a seed value\ntest = df.drop(train.index)\n\n# dependent variable, categorical (0-100)\nYtest = test['volume'].to_numpy()\nYtrain = train['volume'].to_numpy()\n\n# independent variable 1, categorical\n# note : [blues:0, classical:1, country:2, disco:3, hiphop:4, jazz:5, metal:6, pop:7, reggae:8, rock:9]\nle = preprocessing.LabelEncoder()\nX1test = le.fit_transform(test['label'])\nX1train = le.fit_transform(train['label'])\n\n# independent variable 2, numerical\nX2test = test['chroma_stft_mean'].to_numpy()\nX2train = train['chroma_stft_mean'].to_numpy()\n\n# add on the remaining relevant variables here","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.652114Z","iopub.execute_input":"2022-02-10T20:34:36.652675Z","iopub.status.idle":"2022-02-10T20:34:36.686530Z","shell.execute_reply.started":"2022-02-10T20:34:36.652632Z","shell.execute_reply":"2022-02-10T20:34:36.685662Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"# declaring constants\nnumInputs = 2 # number of input variables based on correlation test\nNtest = 200 # number of testing entries\nNtrain = 800 # number of training entries","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.688112Z","iopub.execute_input":"2022-02-10T20:34:36.688667Z","iopub.status.idle":"2022-02-10T20:34:36.693298Z","shell.execute_reply.started":"2022-02-10T20:34:36.688622Z","shell.execute_reply":"2022-02-10T20:34:36.692201Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"# data reshaping\nXtest = np.dstack([X1test,X2test]) # add on all the independent testing variables in this list\nXtest = Xtest.reshape(Ntest,numInputs) \n\nXtrain = np.dstack([X1train,X2train]) # add on all the independent training variables in this list\nXtrain = Xtrain.reshape(Ntrain,numInputs) \n\nYtest = Ytest.reshape(Ntest, 1) # one dependent test variable\nYtrain = Ytrain.reshape(Ntrain, 1) # one dependent train variable\n\n# data type conversion\nxtest = tc.from_numpy(Xtest.astype(np.float32))\nxtrain = tc.from_numpy(Xtrain.astype(np.float32))\n\nytest = tc.from_numpy(Ytest.astype(np.float32))\nytrain = tc.from_numpy(Ytrain.astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.694942Z","iopub.execute_input":"2022-02-10T20:34:36.695501Z","iopub.status.idle":"2022-02-10T20:34:36.706858Z","shell.execute_reply.started":"2022-02-10T20:34:36.695458Z","shell.execute_reply":"2022-02-10T20:34:36.705773Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"# model definition\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.708888Z","iopub.execute_input":"2022-02-10T20:34:36.709231Z","iopub.status.idle":"2022-02-10T20:34:36.719937Z","shell.execute_reply.started":"2022-02-10T20:34:36.709190Z","shell.execute_reply":"2022-02-10T20:34:36.719007Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"# error function & optimizer\nmodel = NeuralNetwork(numInputs)\ne_func = tc.nn.MSELoss()\noptim = tc.optim.SGD(model.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.721547Z","iopub.execute_input":"2022-02-10T20:34:36.722433Z","iopub.status.idle":"2022-02-10T20:34:36.736688Z","shell.execute_reply.started":"2022-02-10T20:34:36.722387Z","shell.execute_reply":"2022-02-10T20:34:36.735828Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"# move model to GPU\ndevice = tc.device(\"cuda\" if tc.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.738680Z","iopub.execute_input":"2022-02-10T20:34:36.739657Z","iopub.status.idle":"2022-02-10T20:34:36.749008Z","shell.execute_reply.started":"2022-02-10T20:34:36.739611Z","shell.execute_reply":"2022-02-10T20:34:36.748050Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"# model training/testing loop\nep = 1000 \ntrain_losses, test_losses, accuracies = [], [], []\n\nfor e in range(ep) :\n    \n    # training model\n    running_loss = 0\n    xtrain, ytrain = xtrain.to(device), ytrain.to(device)\n    \n    optim.zero_grad() \n    \n    output = model(xtrain) \n    loss = e_func(output, ytrain)\n    \n    loss.backward() \n    optim.step() \n    \n    running_loss += loss.item()\n    train_losses.append(running_loss/len(ytrain))\n    \n    # testing model\n    test_loss, accuracy = 0, 0\n    \n    with tc.no_grad():\n            \n        model.eval()\n        xtest, ytest = xtest.to(device), ytest.to(device)\n        output = model(xtest) \n        test_loss += e_func(output, ytest)\n        \n        ps = tc.exp(output)       \n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == ytest.view(*top_class.shape)\n        accuracy += tc.mean(equals.type(tc.FloatTensor))\n        \n    test_losses.append(test_loss/len(ytest))\n    accuracies.append(accuracy/len(ytest))\n    model.train()\n        \n    print(f'Epoch: {e}/{ep}\\n',\n          f'Training loss: {running_loss/len(ytrain)}\\n',\n          f'Test loss: {test_loss/len(ytest)}\\n',\n          f'Accuracy: {accuracy/len(ytest)}\\n')    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:36.750723Z","iopub.execute_input":"2022-02-10T20:34:36.751224Z","iopub.status.idle":"2022-02-10T20:34:39.808585Z","shell.execute_reply.started":"2022-02-10T20:34:36.751182Z","shell.execute_reply":"2022-02-10T20:34:39.807822Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"# plot train & test loss per iteration\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:39.811777Z","iopub.execute_input":"2022-02-10T20:34:39.812151Z","iopub.status.idle":"2022-02-10T20:34:40.038000Z","shell.execute_reply.started":"2022-02-10T20:34:39.812095Z","shell.execute_reply":"2022-02-10T20:34:40.037312Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"# plot testing accuracy\nplt.plot(accuracies, label='Model accuracy')\nplt.legend(frameon=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:40.039177Z","iopub.execute_input":"2022-02-10T20:34:40.040033Z","iopub.status.idle":"2022-02-10T20:34:40.245318Z","shell.execute_reply.started":"2022-02-10T20:34:40.039980Z","shell.execute_reply":"2022-02-10T20:34:40.244601Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"# save model\nPATH = '../output' # input directory in which the model is to be saved\ntc.save(model, PATH)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:40.246437Z","iopub.execute_input":"2022-02-10T20:34:40.247258Z","iopub.status.idle":"2022-02-10T20:34:40.260610Z","shell.execute_reply.started":"2022-02-10T20:34:40.247220Z","shell.execute_reply":"2022-02-10T20:34:40.259945Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"markdown","source":"**Testing model deployment**","metadata":{}},{"cell_type":"code","source":"# model class\nclass NeuralNetwork(nn.Module):\n    def __init__(self, numInputs):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(numInputs, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:40.261877Z","iopub.execute_input":"2022-02-10T20:34:40.262752Z","iopub.status.idle":"2022-02-10T20:34:40.273048Z","shell.execute_reply.started":"2022-02-10T20:34:40.262710Z","shell.execute_reply":"2022-02-10T20:34:40.272352Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"# load model\nPATH = '../output' # directory in which the model is saved\nmodel = tc.load(PATH)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:40.274389Z","iopub.execute_input":"2022-02-10T20:34:40.274824Z","iopub.status.idle":"2022-02-10T20:34:40.292775Z","shell.execute_reply.started":"2022-02-10T20:34:40.274781Z","shell.execute_reply":"2022-02-10T20:34:40.291781Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"# loading sample file for testing\nfname = '../input/test-audio/Kalimba.mp3'\ngenre = '' # specify genre\nSR = 22050\ndata, _ = librosa.load(fname, sr=SR, mono=True)\n\n# visualizing sample mp3\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(y = data, sr = 22050, color = \"#A300F9\")\nplt.title(\"Sound Waves in sample\", fontsize = 10)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:34:40.294780Z","iopub.execute_input":"2022-02-10T20:34:40.295187Z","iopub.status.idle":"2022-02-10T20:35:00.125345Z","shell.execute_reply.started":"2022-02-10T20:34:40.295146Z","shell.execute_reply":"2022-02-10T20:35:00.124561Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"# function to take an mp3 file as a parameter and return predicted volume by calling saved model\ndef predictVolume(data) :\n    \n    # getting all necessary model input values in the correct data format\n    \n    return prediction","metadata":{"execution":{"iopub.status.busy":"2022-02-10T20:35:00.127102Z","iopub.execute_input":"2022-02-10T20:35:00.127567Z","iopub.status.idle":"2022-02-10T20:35:00.132893Z","shell.execute_reply.started":"2022-02-10T20:35:00.127525Z","shell.execute_reply":"2022-02-10T20:35:00.132112Z"},"trusted":true},"execution_count":252,"outputs":[]}]}